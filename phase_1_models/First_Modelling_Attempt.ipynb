{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4ced43",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7cbda72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_files_dynamic import get_super_table\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3d2f2",
   "metadata": {},
   "source": [
    "# Goal of Phase 1 \n",
    "\n",
    "There is a slight change of plans. Instead of breaking up phases 1 and 3, I will do them together.   \n",
    "So the goal is to make a few models. See how long they take to process the data / train the model and make predictions.  \n",
    "For all cases we will tune the model to its best accuracy possible - using as much varaibles as possible   \n",
    "Then after that we will train XX models - one for each camera  \n",
    "To test the speed, we will do   \n",
    "1. single query one model \n",
    "2. multiple query one model \n",
    "3. single query multiple camera \n",
    "4. multiple query multiple camera \n",
    "\n",
    "This will be done for the single model as well as the multiple model  \n",
    "That way we can see the time taken for each  \n",
    "\n",
    "The difference between single and multiple query can be like single is one by one input into the model.  \n",
    "Multiple can be pass in all at one go \n",
    "\n",
    "For the first attempt, i gonna focus on the decision tree since it is the fastest to train so far and is giving good accuracy. Then from there we'll see how to extend to the rest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece551d4",
   "metadata": {},
   "source": [
    "# Get Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60aee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_super_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57f5b948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_timestamp</th>\n",
       "      <th>cam_id</th>\n",
       "      <th>non_rainfall_station_id</th>\n",
       "      <th>rainfall_station_id</th>\n",
       "      <th>2hr_forecast_area</th>\n",
       "      <th>compass</th>\n",
       "      <th>direction</th>\n",
       "      <th>rainfall_realtime</th>\n",
       "      <th>wind_speed_realtime</th>\n",
       "      <th>wind_dir_realtime</th>\n",
       "      <th>...</th>\n",
       "      <th>24hr_period_1_start</th>\n",
       "      <th>24hr_period_1_end</th>\n",
       "      <th>24hr_period_1</th>\n",
       "      <th>24hr_period_2_start</th>\n",
       "      <th>24hr_period_2_end</th>\n",
       "      <th>24hr_period_2</th>\n",
       "      <th>24hr_period_3_start</th>\n",
       "      <th>24hr_period_3_end</th>\n",
       "      <th>24hr_period_3</th>\n",
       "      <th>trafficCongestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-10T034724</td>\n",
       "      <td>1001</td>\n",
       "      <td>S107</td>\n",
       "      <td>S119</td>\n",
       "      <td>Kallang</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-10T000000</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>Partly Cloudy (Night)</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>Partly Cloudy (Day)</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>2022-04-10T180000</td>\n",
       "      <td>Thundery Showers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-10T034724</td>\n",
       "      <td>1001</td>\n",
       "      <td>S107</td>\n",
       "      <td>S119</td>\n",
       "      <td>Kallang</td>\n",
       "      <td>south</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-10T000000</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>Partly Cloudy (Night)</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>Partly Cloudy (Day)</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>2022-04-10T180000</td>\n",
       "      <td>Thundery Showers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-10T034724</td>\n",
       "      <td>1501</td>\n",
       "      <td>S107</td>\n",
       "      <td>S108</td>\n",
       "      <td>City</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-10T000000</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>Partly Cloudy (Night)</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>Partly Cloudy (Day)</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>2022-04-10T180000</td>\n",
       "      <td>Thundery Showers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-10T034724</td>\n",
       "      <td>1502</td>\n",
       "      <td>S107</td>\n",
       "      <td>S108</td>\n",
       "      <td>City</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-10T000000</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>Partly Cloudy (Night)</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>Partly Cloudy (Day)</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>2022-04-10T180000</td>\n",
       "      <td>Thundery Showers</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-10T034724</td>\n",
       "      <td>1503</td>\n",
       "      <td>S107</td>\n",
       "      <td>S108</td>\n",
       "      <td>City</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>325.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-04-10T000000</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>Partly Cloudy (Night)</td>\n",
       "      <td>2022-04-10T060000</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>Partly Cloudy (Day)</td>\n",
       "      <td>2022-04-10T120000</td>\n",
       "      <td>2022-04-10T180000</td>\n",
       "      <td>Thundery Showers</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      call_timestamp  cam_id non_rainfall_station_id rainfall_station_id  \\\n",
       "0  2022-04-10T034724    1001                    S107                S119   \n",
       "1  2022-04-10T034724    1001                    S107                S119   \n",
       "2  2022-04-10T034724    1501                    S107                S108   \n",
       "3  2022-04-10T034724    1502                    S107                S108   \n",
       "4  2022-04-10T034724    1503                    S107                S108   \n",
       "\n",
       "  2hr_forecast_area compass  direction  rainfall_realtime  \\\n",
       "0           Kallang   south          1                0.0   \n",
       "1           Kallang   south          2                0.0   \n",
       "2              City   south          1                0.0   \n",
       "3              City   south          1                0.0   \n",
       "4              City   south          1                0.0   \n",
       "\n",
       "   wind_speed_realtime  wind_dir_realtime  ...  24hr_period_1_start  \\\n",
       "0                  1.2              325.0  ...    2022-04-10T000000   \n",
       "1                  1.2              325.0  ...    2022-04-10T000000   \n",
       "2                  1.2              325.0  ...    2022-04-10T000000   \n",
       "3                  1.2              325.0  ...    2022-04-10T000000   \n",
       "4                  1.2              325.0  ...    2022-04-10T000000   \n",
       "\n",
       "   24hr_period_1_end          24hr_period_1 24hr_period_2_start  \\\n",
       "0  2022-04-10T060000  Partly Cloudy (Night)   2022-04-10T060000   \n",
       "1  2022-04-10T060000  Partly Cloudy (Night)   2022-04-10T060000   \n",
       "2  2022-04-10T060000  Partly Cloudy (Night)   2022-04-10T060000   \n",
       "3  2022-04-10T060000  Partly Cloudy (Night)   2022-04-10T060000   \n",
       "4  2022-04-10T060000  Partly Cloudy (Night)   2022-04-10T060000   \n",
       "\n",
       "   24hr_period_2_end        24hr_period_2 24hr_period_3_start  \\\n",
       "0  2022-04-10T120000  Partly Cloudy (Day)   2022-04-10T120000   \n",
       "1  2022-04-10T120000  Partly Cloudy (Day)   2022-04-10T120000   \n",
       "2  2022-04-10T120000  Partly Cloudy (Day)   2022-04-10T120000   \n",
       "3  2022-04-10T120000  Partly Cloudy (Day)   2022-04-10T120000   \n",
       "4  2022-04-10T120000  Partly Cloudy (Day)   2022-04-10T120000   \n",
       "\n",
       "   24hr_period_3_end     24hr_period_3  trafficCongestion  \n",
       "0  2022-04-10T180000  Thundery Showers               None  \n",
       "1  2022-04-10T180000  Thundery Showers               None  \n",
       "2  2022-04-10T180000  Thundery Showers               None  \n",
       "3  2022-04-10T180000  Thundery Showers               None  \n",
       "4  2022-04-10T180000  Thundery Showers             Medium  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd48ccd",
   "metadata": {},
   "source": [
    "# Some transformations needed for all \n",
    "\n",
    "Note that i still kept the station/area identifiers.  \n",
    "Should probably drop them but i think will drop later manually when needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92db7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May just end up dropping since too much effort to convert and very little values \n",
    "df.call_timestamp = pd.to_datetime(df.call_timestamp)\n",
    "df[\"24hr_start\"] = pd.to_datetime(df[\"24hr_start\"])\n",
    "df[\"24hr_end\"] = pd.to_datetime(df[\"24hr_end\"])\n",
    "df[\"24hr_period_1_start\"] = pd.to_datetime(df[\"24hr_period_1_start\"])\n",
    "df[\"24hr_period_1_end\"] = pd.to_datetime(df[\"24hr_period_1_end\"])\n",
    "df[\"24hr_period_2_start\"] = pd.to_datetime(df[\"24hr_period_2_start\"])\n",
    "df[\"24hr_period_2_end\"] = pd.to_datetime(df[\"24hr_period_2_end\"])\n",
    "df[\"24hr_period_3_start\"] = pd.to_datetime(df[\"24hr_period_3_start\"])\n",
    "df[\"24hr_period_3_end\"] = pd.to_datetime(df[\"24hr_period_3_end\"])\n",
    "\n",
    "# Make dummy values\n",
    "dummy_df = pd.get_dummies(df.drop([\"trafficCongestion\", \"rainfall_station_id\", \"non_rainfall_station_id\",\n",
    "                                 \"2hr_forecast_area\", \"compass\"], axis = 1))\n",
    "df_keep = df[[\"trafficCongestion\", \"rainfall_station_id\", \"non_rainfall_station_id\", \"2hr_forecast_area\", \"compass\"]]\n",
    "\n",
    "# reform with dropped values \n",
    "dummy_df = pd.merge(dummy_df, df_keep, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a91993",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df[[\"rainfall_realtime\", \"wind_speed_realtime\", \"wind_dir_realtime\", 'humidity_realtime', 'air_temp_realtime', \n",
    "           '4day_temperature_low_1', '4day_temperature_low_2', '4day_temperature_low_3', '4day_temperature_low_4',\n",
    "           '4day_temperature_high_1', '4day_temperature_high_2', '4day_temperature_high_3', '4day_temperature_high_4',\n",
    "           '4day_relative_humidity_low_1', '4day_relative_humidity_low_2','4day_relative_humidity_low_3',\n",
    "           '4day_relative_humidity_low_4', '4day_relative_humidity_high_1', '4day_relative_humidity_high_2',\n",
    "           '4day_relative_humidity_high_3', '4day_relative_humidity_high_4','4day_wind_speed_low_1',\n",
    "           '4day_wind_speed_low_2', '4day_wind_speed_low_3', '4day_wind_speed_low_4','4day_wind_speed_high_1',\n",
    "           '4day_wind_speed_high_2','4day_wind_speed_high_3', '4day_wind_speed_high_4', \n",
    "           '24hr_general_relative_humidity_low','24hr_general_relative_humidity_high', '24hr_general_temperature_low',\n",
    "           '24hr_general_temperature_high', '24hr_general_wind_speed_low', '24hr_general_wind_speed_high', \n",
    "           \"trafficCongestion\", \n",
    "          \"cam_id\", \"direction\", \"rainfall_station_id\", \"non_rainfall_station_id\", \"2hr_forecast_area\", \"compass\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "422f6775",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drop_identifiers = [\"rainfall_station_id\", \"non_rainfall_station_id\", \"2hr_forecast_area\", \"compass\"]\n",
    "drop_camera = [\"cam_id\", \"direction\"]\n",
    "drop_time = [\"call_timestamp\", \"24hr_start\", \"24hr_end\", \"24hr_period_1_start\", \"24hr_period_1_end\",\n",
    "            \"24hr_period_2_start\", \"24hr_period_2_end\", \"24hr_period_3_start\", \"24hr_period_3_end\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c68d37",
   "metadata": {},
   "source": [
    "# Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8855b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(predicted, actual):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    cmd = ConfusionMatrixDisplay(cm)\n",
    "    cmd.plot(colorbar= False, cmap = \"binary\")\n",
    "    \n",
    "def get_confusion(predicted, actual):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    return pd.DataFrame(cm)\n",
    "\n",
    "def get_accuracy(predicted, actual):\n",
    "    return np.mean(predicted == actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1b2e3",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "For the first single tree will use the numeric without the identifiers \n",
    "By right need validation step for the tuning process but will skip for now since it is just a prototype\n",
    "\n",
    "But apparently the camera id damn good for predicting. \n",
    "Time doesnt work for the decision tree model - if want to use will need more pre-processing \n",
    "\n",
    "## Single Model, Dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbd1497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dummy_df.drop(drop_identifiers, axis = 1)\n",
    "#df = df.drop(drop_camera, axis = 1)\n",
    "df = df.drop(drop_time, axis = 1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = df.trafficCongestion.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c740c412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train decision tree is 1.1902\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train decision tree is {end_time - start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5dd22643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34579b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.8551817144437913\n",
      "The time taken to predict is 30.0284 seconds\n"
     ]
    }
   ],
   "source": [
    "# Single Query \n",
    "acc = []\n",
    "start_time = time.perf_counter()\n",
    "for i in range(len(X_test)):\n",
    "    accuracy = get_accuracy(y_test[i], clf.predict(X_test.iloc[i:i+1,:]))\n",
    "    acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "86547d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.8551817144437913\n",
      "The time taken to predict is 0.0264 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multiple Query \n",
    "start_time = time.perf_counter()\n",
    "accuracy = get_accuracy(y_test, clf.predict(X_test))\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The accuracy is: {accuracy}\")\n",
    "print(f\"The time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffdd151",
   "metadata": {},
   "source": [
    "## Single Model, Numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9696432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = numeric_df.drop(drop_identifiers, axis = 1)\n",
    "df = df.drop(drop_camera, axis = 1)\n",
    "#df = df.drop(drop_time, axis = 1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = df.trafficCongestion.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8d875bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train decision tree is 0.2732\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train decision tree is {end_time - start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d1670de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b02f6514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.5853591064697949\n",
      "The time taken to predict is 24.1547 seconds\n"
     ]
    }
   ],
   "source": [
    "# Single Query \n",
    "acc = []\n",
    "start_time = time.perf_counter()\n",
    "for i in range(len(X_test)):\n",
    "    accuracy = get_accuracy(y_test[i], clf.predict(X_test.iloc[i:i+1,:]))\n",
    "    acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93a80399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.5853591064697949\n",
      "The time taken to predict is 0.0126 seconds\n"
     ]
    }
   ],
   "source": [
    "# Mutliple Query \n",
    "start_time = time.perf_counter()\n",
    "accuracy = get_accuracy(y_test, clf.predict(X_test))\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The accuracy is: {accuracy}\")\n",
    "print(f\"The time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e382ec",
   "metadata": {},
   "source": [
    "# Multiple Models, dummy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9df32b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train all the decision trees are 0.6916\n"
     ]
    }
   ],
   "source": [
    "df = dummy_df.drop(drop_identifiers, axis = 1)\n",
    "#df = df.drop(drop_camera, axis = 1)\n",
    "df = df.drop(drop_time, axis = 1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = df.trafficCongestion.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "all_camera = dummy_df.cam_id.unique()\n",
    "all_models = {}\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for cam in all_camera:\n",
    "    index = X_train.cam_id == cam\n",
    "    train_x = X_train[index]\n",
    "    train_y = y_train[index]\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=0).fit(train_x, train_y)\n",
    "    \n",
    "    all_models[cam] = clf\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train all the decision trees are {end_time - start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7c1a1653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 0.8551125557591894\n",
      "The total time taken to predict is 46.1182 seconds\n"
     ]
    }
   ],
   "source": [
    "# Sinle Query \n",
    "start_time = time.perf_counter()\n",
    "acc = []\n",
    "for cam in all_camera:\n",
    "    index = X_test.cam_id == cam\n",
    "    for i in range(sum(index)):\n",
    "        accuracy = get_accuracy(y_test[index][i], all_models[cam].predict(X_test[index].iloc[i:i+1,:]))\n",
    "        acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The average accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The total time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3d7accf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 0.8554581816540641\n",
      "The total time taken to predict is 0.1569 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multiple Query \n",
    "start_time = time.perf_counter()\n",
    "acc = []\n",
    "for cam in all_camera:\n",
    "    index = X_test.cam_id == cam\n",
    "    accuracy = get_accuracy(y_test[index], all_models[cam].predict(X_test[index]))\n",
    "    acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The average accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The total time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3707f921",
   "metadata": {},
   "source": [
    "# Multiple Models Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5cc55945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train all the decision trees are 0.5419\n"
     ]
    }
   ],
   "source": [
    "df = numeric_df.drop(drop_identifiers, axis = 1)\n",
    "#df = df.drop(drop_camera, axis = 1)\n",
    "#df = df.drop(drop_time, axis = 1)\n",
    "df = df.dropna()\n",
    "\n",
    "X = df.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = df.trafficCongestion.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "all_camera = dummy_df.cam_id.unique()\n",
    "all_models = {}\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for cam in all_camera:\n",
    "    index = X_train.cam_id == cam\n",
    "    train_x = X_train[index]\n",
    "    train_y = y_train[index]\n",
    "    \n",
    "    clf = DecisionTreeClassifier(random_state=0).fit(train_x, train_y)\n",
    "    \n",
    "    all_models[cam] = clf\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train all the decision trees are {end_time - start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e787ec1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 0.8498910750717521\n",
      "The total time taken to predict is 33.5791 seconds\n"
     ]
    }
   ],
   "source": [
    "# Single Query \n",
    "start_time = time.perf_counter()\n",
    "acc = []\n",
    "for cam in all_camera:\n",
    "    index = X_test.cam_id == cam\n",
    "    for i in range(sum(index)):\n",
    "        accuracy = get_accuracy(y_test[index][i], all_models[cam].predict(X_test[index].iloc[i:i+1,:]))\n",
    "        acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The average accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The total time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4b9591a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy is: 0.8495409168841885\n",
      "The total time taken to predict is 0.1183 seconds\n"
     ]
    }
   ],
   "source": [
    "# Multiple Query \n",
    "start_time = time.perf_counter()\n",
    "acc = []\n",
    "for cam in all_camera:\n",
    "    index = X_test.cam_id == cam\n",
    "    accuracy = get_accuracy(y_test[index], all_models[cam].predict(X_test[index]))\n",
    "    acc.append(accuracy)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The average accuracy is: {np.mean(acc)}\")\n",
    "print(f\"The total time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38b8da",
   "metadata": {},
   "source": [
    "# The rest below can ignore "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b09f6",
   "metadata": {},
   "source": [
    "# Model Attempt 1 \n",
    "For ease of modelling, i will only deal with a logisitic linear model consisiting only of the numerical variables. For ease of modelling, any rows with NA will be dropped. No distingushing factor of the stations will alos be considered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5967dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = data.trafficCongestion.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "689a5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train Logsitic Regression is 144.6573\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "clf = LogisticRegression(random_state=0, max_iter = 10000).fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train Logsitic Regression is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7056ada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZMUlEQVR4nO3deXRUZbrv8e9DJtEwCaGXhCkhXA6jRKJI98HmiDagqEebIfawbDi0R/Fqg7qWU3dzxKVNe7yiXHRdchsR+xxxgPbiiG0ztNoOGDmtlwheEDWDDQkgMkRJUj73j9opg52EALWroPh91qpl7V1Vez8vpn717ndP5u6IiLRLdgEicnxQGIgIoDAQkYDCQEQAhYGIBNKTXUBT3bp18759+ya7DJGU9cknn7Bz505r7rXjKgz69u1LaWlpsssQSVlFRUUtvqbNBBEBFAYiElAYiAigMBCRgMJARACFgYgEFAYiAigMRCSgMBARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQESAkzAMVq1axYABAygoKGDevHnJLieuUrVtaleCuHtoD2A88CGwFbj1cO8fMWKEh6mhocHz8/P9o48+8oMHD/qwYcO8rKws1HUmSqq2Te2Kr+A71uz3L7SegZmlAQ8BE4BBwJVmNiis9bXF+vXrKSgoID8/n8zMTIqLi1m5cmUyS4qbVG2b2pU4YW4mnANsdfdt7l4HPAFcFuL6DquqqopevXrFpnv27ElVVVUSK4qfVG2b2pU4YYZBLlDRZLoymCcix6GkDyCa2dVmVmpmpTU1NaGuKzc3l4qKb/KpsrKS3NzUyKdUbZvalUAtDSYc6wMYBbzcZPo24LbWPhP2AGJ9fb3n5eX5tm3bYoM2GzduDHWdiZKqbVO74qu1AcQwb7z6DtDfzPKAKqAY+FGI6zus9PR0Fi5cyLhx44hEIkyfPp3Bgwcns6S4SdW2qV2JYx791Q5n4WYXAQ8AacAj7n53a+8vKipy3YVZJDxFRUWUlpYm/pbs7v4i8GKY6xCR+Ej6AKKIHB8UBiICKAxEJKAwEBFAYSAiAYWBiAAKAxEJKAxEBFAYiEhAYSAigMJARAIKAxEBFAYiElAYiAigMBCRgMJARACFgYgEFAYiAigMRCSgMBARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISOOnCYNWqVQwYMICCggLmzZuX7HLiKlXbpnYliLuH8gAeAaqBjW39zIgRIzxMDQ0Nnp+f7x999JEfPHjQhw0b5mVlZaGuM1FStW1qV3wF37Fmv39h9gweBcaHuPwjtn79egoKCsjPzyczM5Pi4mJWrlyZ7LLiIlXbpnYlTmhh4O6vArvDWv7RqKqqolevXrHpnj17UlVVlcSK4idV26Z2JU7SxwzM7GozKzWz0pqammSXI3LSSnoYuHuJuxe5e1FOTk6o68rNzaWioiI2XVlZSW5ubqjrTJRUbZvalUAtDSbE4wH05TgaQKyvr/e8vDzftm1bbNBm48aNoa4zUVK1bWpXfLU2gJie3ChKrPT0dBYuXMi4ceOIRCJMnz6dwYMHJ7usuEjVtqldiWMe/QWP/4LNlgFjgG7ADmCOuy9u7TNFRUVeWloaSj0iAkVFRZSWllpzr7XYMzCz/wm0mBTufkNrK3X3K9tcoYgkXWubCfqJFjmJtBgG7r606bSZneruteGXJCLJcNhdi2Y2ysw+ADYH02ea2cOhVyYiCdWW4wweAMYBuwDc/T3gvBBrEpEkaNNBR+5e8a1ZkRBqEZEkastxBhVm9l3AzSwD+AWwKdyyRCTR2tIzuAa4DsgFPgOGB9MikkIO2zNw953AjxNQi4gkUVv2JuSb2XNmVmNm1Wa20szyE1GciCROWzYTHgeeAs4AegBPA8vCLEpEEq8tYXCqu//e3RuCx38Ap4RdmIgkVmvnJpwePH3JzG4FniB6rsJU4MUE1CYiCdTaAOK7RL/8jWc4/WuT1xy4LayiRCTxWjs3IS+RhYhIcrXp4iZmNgQYRJOxAnd/LKyiRCTxDhsGZjaH6EVKBhEdK5gAvA4oDERSSFv2JkwCxgLb3X0acCbQKdSqRCTh2hIGX7r710CDmXUkepekXof5jIicYNoyZlBqZp2B/010D8N+4M0wixKRxGvLuQkzg6f/y8xWAR3d/f1wyxKRRGvtoKOzWnvN3TeEU5KIJENrPYP/0cprDpwf51pEJIlaO+jonxJZiIgkV9LvtSgixweFgYgACgMRCbTlSkdmZj8xs18H073N7JzwSxORRGpLz+BhYBTQeO/EfcBDoVUkIknRliMQR7r7WWb2XwDu/rmZZYZcl4gkWFt6BvVmlkZwR2YzywG+DrUqEUm4toTBAuAZoLuZ3U309OV7Qq1KRBKuLecm/KeZvUv0NGYD/tnddUclkRTTloub9AZqgeeaznP38jALE5HEassA4gt8c2HUU4A84ENgcIh1iUiCtWUzYWjT6eBsxpktvF1ETlBHfARicOryyBBqEZEkasuYwY1NJtsBZxG9G7OIpJC2jBl0aPK8gegYwopwyhGRZGk1DIKDjTq4+80JqkdEkqTFMQMzS3f3CPC9BNYjIknSWs9gPdHxgb+a2bNEb8V+oPFFd/9DyLWJSAK1ZczgFGAX0WseNh5v4IDCQCSFtBYG3YM9CRs59G7MBNMikkJaC4M0IJtDQ6CRwkAkxbR20NHf3H2uu9/ZzGNuwiqMs1WrVjFgwAAKCgqYN29essuJq1Rtm9qVIO7e7AP4r5Zea8uD6P0Y1wIfAGXALw73mREjRniYGhoaPD8/3z/66CM/ePCgDxs2zMvKykJdZ6KkatvUrvgKvmPNfv9a6xmMPcacaQBucvdBwLnAdWY26BiXeUzWr19PQUEB+fn5ZGZmUlxczMqVK5NZUtykatvUrsRpMQzcffexLNjd/+bBLdjcfR+wCcg9lmUeq6qqKnr1+uYG0j179qSqqiqJFcVPqrZN7UqchFwq3cz6AoXA2828drWZlZpZaU1NTSLKEZFmhB4GZpZN9FyGWe6+99uvu3uJuxe5e1FOTk6oteTm5lJRURGbrqysJDc3qZ2VuEnVtqldCdTSYEI8HkAG8DJwY1veH/YAYn19vefl5fm2bdtigzYbN24MdZ2JkqptU7viq7UBxLYcgXhUzMyAxcAmd78/rPUcifT0dBYuXMi4ceOIRCJMnz6dwYNT44JNqdo2tStxzD2c44fM7B+B14D/yzeXVr/d3V9s6TNFRUVeWloaSj0iAkVFRZSWljZ3IGF4PQN3f53mj14UkeOQbrwqIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISUBiICBDi1ZGPxpdffsnGjRuTXUbcvf32391VLmWcf/75yS4hFPn5+ckuIeHUMxARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISOC4ulT6sdi+fTu33347u3btwsyYNGkSP/nJT/jwww+ZO3cutbW15ObmMm/ePLKzs3njjTd44IEHqK+vJyMjg5tuuomRI0cCsGDBAp599ln27t3L+vXrk9wyqK2tZenSpVRVVQEwbdo0+vXrx+rVq1m7di3t2rVj6NChTJ48mbKyMlasWEEkEiEtLY3JkyczcOBAAO69916++OILMjMzAZg9ezYdO3ZMWrs+++wzbr75Znbu3ImZUVxczLRp0/jNb37D6tWrycjIoE+fPtx777107NiRyspKLrzwwthlzIcPH87dd98NwM9+9jOqq6uJRCIUFRUxd+5c0tLSEtaWxYsXM3HiRKqrqxk6dCgATzzxBAMGDACgc+fO7Nmzh8LCQk4//XSWL1/O2WefzaOPPsr1118PQPv27Xn66afp168fkUiE5557jttuuw2AzMxMHnvsMUaMGMGuXbuYOnUqn376aVzbYO4e1wXGFmx2CvAqkEU0dJa7+5zWPjN48GB/8sknj2p9NTU11NTUMGjQIA4cOMDUqVN58MEHueOOO7jppps4++yzeeaZZ6isrOT6669n06ZNdO3ale7du7NlyxauueYaVq9eDcB7771Hjx49uPjii+MSBsd634TFixfTv39/zjvvPBoaGqirq6O8vJwXXniBG264gYyMDPbu3UvHjh0pLy+nY8eOdO7cmaqqKubPn899990HRMNgypQp9O3b95jb1OhY7ptQXV1NdXU1Q4YMYf/+/Vx66aUsWrSI7du3M2rUKNLT05k3bx4At956K5WVlcyYMYNVq1b93bL27dtHhw4dcHdmzpzJRRddxCWXXHLUtR3pfRNGjx7N/v37eeyxx2Jh0NR9993HF198wV133cWpp55KYWEhQ4YMYciQIYeEwciRI1m3bh0ZGRmsXr2ae+65h1WrVnHttdcybNgwrr32WqZOncrll19OcXHxUbXN3a25+WFuJhwEznf3M4HhwHgzOzesleXk5DBo0CAATjvtNPLy8tixYweffvopRUVFAIwaNYo//elPAAwcOJDu3bsDUFBQwFdffUVdXR0AZ555Jjk5OWGVekRqa2vZsmULo0ePBiA9PZ1TTz2VdevWMWHCBDIyMgBiv/C9e/emc+fOAPTo0YO6ujrq6+uTUvvhdO/enSFDhgCQnZ1NQUEB27dvZ/To0aSnRzuthYWFbN++/bDL6tChAwANDQ3U19dj1uzfe2hee+01du/e3eLrU6ZMYdmyZUD0/+lf/vIXvvrqq0Pe8+WXX7Ju3ToA6uvr2bBhAz179gTgsssuY+nSpQAsX76csWPHxr0NoW0meLTLsT+YzAge4XRDvqWqqorNmzczbNgw+vXrx5o1axg7diwvv/xys39Yr7zyCgMHDox1n48nO3fuJDs7myVLllBRUUGfPn248sor2bFjB1u2bOGZZ54hIyODyZMnk5eXd8hn3333Xfr06RMLDIAlS5bQrl07zjrrLCZOnJjwL01LKisrKSsrY/jw4YfMf/rpp5k4cWJsuqKigokTJ5Kdnc2NN97IOeecE3vtqquu4r333uP73/8+EyZMSFTphzV69Gh27NjB1q1b2/yZTp06cckll/Dggw8CkJubS0VFBQCRSIQvvviCrl27smvXrrjVGeoAopmlmdlfgWrgFXcP/T5jtbW1zJ49m1tuuYXs7Gzmzp3Lk08+yZQpU6itrT3kiwGwdetW5s+fz5w5rW7BJM3XX39NeXk5Y8aMYc6cOWRlZfHSSy8RiUQ4cOAAt99+O5MmTWLRokU03eSrqqpixYoV/PSnP43N+/nPf86dd97JLbfcwpYtW3jzzTeT0aS/c+DAAWbOnMmvfvWr2C88wEMPPUR6ejqXXXYZEO39vf766zz//PPccccdzJ49m3379sXev3TpUt5++23q6up44403Et6Ollx55ZWxXkFbpKWlsWzZMhYsWMDHH38cYmWHCjUM3D3i7sOBnsA5Zjbk2+8xs6vNrNTMSj///PNjWl99fT2zZ8/m4osv5oILLgCi234lJSU89dRTTJgwgV69esXev337dmbNmsU999xzyPzjSZcuXejSpUtsG3bEiBF8+umndOnShbPOOgszIz8/HzNj//5oR2z37t08/PDDTJ8+PbYp1LgsgFNOOYWRI0cm9A+tJfX19cycOZNLL72U8ePHx+YvX76cNWvWMH/+/FjvJSsrK9aGoUOH0rt3779rQ1ZWFhdeeGFsczDZ0tLSuOKKKziSsbCSkhK2bNkS6xVANNwb/0bT0tLo1KlTXHsFkKBdi+6+B1gLjG/mtRJ3L3L3osb/0Ue5DubMmUN+fj5XXXVVbH7jP9jXX39NSUkJU6ZMAWDv3r1cd911zJo1i8LCwqNeb9g6derE6aefHtu82bRpEz169KCwsJDNmzcD0VBraGggOzub2tpaFixYwBVXXEH//v1jy4lEIrFf0YaGBt5//31yc3MT36Am3J1bb72Vfv36MWPGjNj8P//5z5SUlFBSUkL79u1j83ft2kUkEgGgvLycTz75hN69e3PgwAGqq6uBaNvWrl1Lv379EtuYFlxwwQVs3rw5tifocO666y46derErFmzDpn/7LPPxv6uJ02axJo1a+Jdaqh7E3KAenffY2btgT8Cv3X351v6zLHsTdiwYQNXXXUV/fv3p127aMbdcMMNlJeX88QTTwAwduxYZs2ahZmxaNEiFi9eTO/evWPLWLRoEV27duX+++/nhRdeoKamhpycHH74wx8yc+bMo6oLjn1vQnl5OUuXLqWhoYGcnBymTZtGVlZWbBwhPT09tgvx+eef58UXX+Q73/lO7POzZ88mKyuL3/72t0QiEdydgQMHMnXq1Ni/1dE6lr0J77zzDlOnTmXAgAGxOm6++Wbmzp1LXV1dbCC0cRfiSy+9xAMPPEB6ejrt2rVj1qxZjB07lpqaGmbMmEFdXR3uzrnnnssvf/nL2CDk0TjSvQmPP/44Y8aMoVu3buzYsYM5c+bwyCOPsGTJEt566y0WLVp0yPs//vhjOnbsSGZmJnv27OEHP/gBe/fupbKykk2bNnHw4EEAFi5cyOLFi8nKyuL3v/89hYWF7N69m+Li4qPu2bW0NyHMMBgGLAXSiPZAnnL3ua195ljC4HimW7KfeFL5luwthUGYexPeB47f/reIHEKHI4sIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISUBiICKAwEJGAwkBEAIWBiAQUBiICKAxEJBDafROOhpnVAPG96XzLugE7E7SuRFK7TjyJbFsfd2/2FuPHVRgkkpmVuntRsuuIN7XrxHO8tE2bCSICKAxEJHAyh0FJsgsIidp14jku2nbSjhmIyKFO5p6BiDShMBAR4CQMAzMbb2YfmtlWM7s12fXEi5k9YmbVZrYx2bXEk5n1MrO1ZvaBmZWZ2S+SXVM8mNkpZrbezN4L2nVn0ms6mcYMzCwN+H/AhUAl8A5wpbt/kNTC4sDMzgP2A4+5+5Bk1xMvZnYGcIa7bzCzDsC7wD+f6P/PzMyA09x9v5llAK8Dv3D3t5JV08nWMzgH2Oru29y9DngCuCzJNcWFu78K7E52HfHm7n9z9w3B833AJiA3uVUdO4/aH0xmBI+k/jKfbGGQC1Q0ma4kBf6wThZm1hcoBN5OcilxYWZpZvZXoBp4xd2T2q6TLQzkBGVm2cAKYJa77012PfHg7hF3Hw70BM4xs6Ru3p1sYVAF9Goy3TOYJ8exYJt6BfCf7v6HZNcTb+6+B1gLjE9mHSdbGLwD9DezPDPLBIqBZ5Nck7QiGGhbDGxy9/uTXU+8mFmOmXUOnrcnOqi9OZk1nVRh4O4NwH8HXiY6EPWUu5clt6r4MLNlwJvAADOrNLN/SXZNcfI94KfA+Wb21+BxUbKLioMzgLVm9j7RH6lX3P35ZBZ0Uu1aFJGWnVQ9AxFpmcJARACFgYgEFAYiAigMRCSgMDiBmFkk2LW20cyeNrNTj2FZj5rZpOD578xsUCvvHWNm3z2KdXxiZt3aOv9b79nf2uvNvP/fzOzmI61RvqEwOLF86e7Dg7MS64Brmr5oZulHs1B3n3GYswDHAEccBnJiURicuF4DCoJf7dfM7Fngg+Dkl383s3fM7H0z+1eIHslnZguDazn8CejeuCAzW2dmRcHz8Wa2ITjPfnVwctA1wOygVzI6OHpuRbCOd8zse8Fnu5rZH4Pz838H2OEaYWb/x8zeDT5z9bdemx/MX21mOcG8fma2KvjMa2b2D3H51xRwdz1OkAewP/hvOrASuJbor/YBIC947Wrgl8HzLKAUyAOuAF4B0oAewB5gUvC+dUARkEP0rM7GZZ0e/PffgJub1PE48I/B895EDxUGWAD8Onh+MdFTcrs1045PGuc3WUd7YCPQNZh24MfB818DC4Pnq4H+wfORwJrmatTjyB9H1a2UpGkfnPIK0Z7BYqLd9/Xu/nEw/wfAsMbxAKAT0B84D1jm7hHgMzNb08zyzwVebVyWu7d0fYQLgEHR0wYA6BicVXge0dDB3V8ws8/b0KYbzOzy4HmvoNZdwNfAk8H8/wD+EKzju8DTTdad1YZ1SBsoDE4sX3r0lNeY4EtxoOks4Hp3f/lb74vn8fztgHPd/atmamkzMxtDNFhGuXutma0DTmnh7R6sd8+3/w0kPjRmkHpeBq4NTvvFzP6bmZ0GvApMDcYUzgD+qZnPvgWcZ2Z5wWdPD+bvAzo0ed8fgesbJ8xsePD0VeBHwbwJQJfD1NoJ+DwIgn8g2jNp1A5o7N38CHjdo9cx+NjMJgfrMDM78zDrkDZSGKSe3wEfABssenHURUR7gM8AW4LXHiN6huMh3L2G6JjDH8zsPb7ppj8HXN44gAjcABQFA5Qf8M1ejTuJhkkZ0c2F8sPUugpIN7NNwDyiYdToANELfmwEzgfmBvN/DPxLUF8ZKXLZuuOBzloUEUA9AxEJKAxEBFAYiEhAYSAigMJARAIKAxEBFAYiEvj/wm7D8zYPSz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77461739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.5919983401915696\n",
      "The time taken to predict is 0.0124 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "accuracy = get_accuracy(y_test, clf.predict(X_test))\n",
    "end_time = time.perf_counter()\n",
    "print(f\"The accuracy is: {accuracy}\")\n",
    "print(f\"The time taken to predict is {end_time - start_time:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c1dd8",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "So \"fresh start\" and ignore the rest.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d80621b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"trafficCongestion\", axis = 1)\n",
    "Y = df.trafficCongestion.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593fbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5718b81",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The DType <class 'numpy.dtype[int64]'> could not be promoted by <class 'numpy.dtype[datetime64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m----> 2\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime to train decision tree is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time \u001b[38;5;241m-\u001b[39m start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\sklearn\\tree\\_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    169\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\sklearn\\base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_separately:\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# :(\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     check_X_params, check_y_params \u001b[38;5;241m=\u001b[39m validate_separately\n\u001b[1;32m--> 578\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:665\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    662\u001b[0m                     has_pd_integer_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 665\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype_orig\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    669\u001b[0m         \u001b[38;5;66;03m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The DType <class 'numpy.dtype[int64]'> could not be promoted by <class 'numpy.dtype[datetime64]'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[float64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[int64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[datetime64]'>, <class 'numpy.dtype[object_]'>)"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Time to train decision tree is {end_time - start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed98218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAniElEQVR4nO3deXyNZ/7/8dcniS1ibRCSxtpWbFlEgpbGjJ3SBFOio6olk1Y77TDDdKrKlxmKLkrpoml1LFNLW/qzK7VMQxIStbS6pZamJAiR0GzX749zOyNFBGdBP8/H4zycc597+dySvM91X/e570uMMSillIe7C1BK3Rw0DJRSgIaBUsqiYaCUAjQMlFIWL3cXcLGaNWuagIAAd5fhcF5eN9V/s0N5eOjnya0kPT2drKwsudx7N9VvaUBAACtWrHB3GQ5Xu3Ztd5fgNN7e3u4uwSmKi4vdXYJTREREXPE9jXWlFKBhoJSyaBgopQANA6WURcNAKQVoGCilLBoGSilAw0ApZdEwUEoBGgZKKYuGgVIK0DBQSlk0DJRSgIaBUsqiYaCUAjQMlFIWDQOlFKBhoJSyaBgopQANA6WURcNAKQXcRmHw008/MWjQILp06ULXrl1JSEgAIDs7m4cffphOnTrx8MMPc/r0aQASExNp1aoVPXv2pGfPnsycOdO+rvvuu4/u3bvTs2dP+vTp45b9uZLs7GwGDx5MaGgoYWFh7Nixg7S0NKKiomjbti333XcfycnJAHz99dd06tSJGjVq8Oqrr7q38GvUoEEDWrZsSUhICOHh4QAsWbKE5s2b4+HhYd/HW8Fjjz2Gn58frVq1sk9LTU2lffv2hIWFERERwc6dO0ssk5SURPny5Vm6dKnL6nTqrdJFpDvwGuAJvGOMmeKsbXl5efGPf/yDFi1acPbsWR544AHuu+8+li5dyr333kt8fDxz5sxhzpw5jB07FoA2bdowb968y65v4cKF1KxZ01nlXre//vWvdOnShQULFpCfn09eXh5//OMf+fvf/063bt1Ys2YNzz//PGvWrKFGjRpMnz6dlStXurvs67Jp0yZ8fX3tr1u0aMHy5cuJi4tzY1XX7pFHHuHJJ59k6NCh9mljxoxh3Lhx9OjRg1WrVjF27Fg+++wzAIqKivj73/9Oly5dXFqn01oGIuIJzAZ6AM2AQSLSzFnbq127Ni1atADAx8eHJk2a8PPPP7N+/Xr69esHQL9+/Vi3bp2zSnC606dPs337dh555BEAypcvT/Xq1RERcnJyADhz5gx+fn6A7f+kdevWlCtXzm01O1JQUBD33HOPu8u4Zh07drzkg0VEOHPmDGD7udatW9f+3qxZs4iJiXH5eBvObBlEAN8aY74HEJHFQF9gvxO3CcCRI0fYv38/ISEhZGVl2f9Ta9WqRVZWln2+Xbt20aNHD+rUqcNzzz3H3XffjVUrQ4YMQUQYNGgQsbGxzi65TNLT0/H19SUuLo4vv/yS0NBQpk2bxksvvUTfvn157rnnKC4utn/C3MpEhK5duyIixMXFMWLECHeX5FCvvPIKPXr04G9/+xvFxcVs27YNgKNHj/Lxxx+zceNGkpKSXFqTM/sM/IHDF70+Yk1zqtzcXOLj4xk3bhxVqlQp8Z6IIGIbWap58+Zs27aN1atX88gjj5Roei5ZsoRPP/2UhIQEPvjgA3bs2OHsssukqKiI1NRUhg8fzhdffIG3tzczZszgnXfeYerUqRw8eJCpU6cSHx/v7lJv2LZt29i1axerV69m9uzZbNmyxd0lOdTcuXOZMWMGP/74IzNmzGD48OEAPPvss/zrX/9yy7B1bu9AFJERIpIsIsknTpy4oXUVFBQQHx9P37596d69OwC+vr4cP34cgOPHj3PHHXcAUKVKFSpXrgxAp06dKCgo4OTJkwD2Zravry/dunUjLS3thupylHr16uHv70+bNm0AiI6OJjU1lQULFtC3b18AYmJiSElJcWeZDuHvb/vcqF27NtHR0Zd0sN3q5s+fT0xMDAADBgyw719KSgqxsbE0atSIZcuWMXLkSD7++GOX1OTMMDgK3HnR6wBrWgnGmLeMMeHGmPALf6jXwxjDmDFjaNKkCY8//rh9eufOnVm2bBkAy5Yts3fKZGZmYowBbD27xhhq1KhBXl4eZ8+eBSAvL4+tW7feNMepfn5+BAQEcPDgQQA2b95M06ZNqVu3Llu3brVPa9y4sTvLvGG5ubn2PpDc3FzWrVtn7w+6XdSrV4/PP/8cgM8++4y77roLgO+++47vv/+e77//nn79+jFr1iwefPBBl9TkzD6DJOAuEWmILQQGAk47+E5OTuajjz7innvuoWfPnoCt5z0+Pp6RI0fy4Ycf4u/vz6xZswBYtWoVCxYswNPTk4oVKzJz5kxEhKysLPshQ1FREX369OH+++93VtnXbPr06QwbNoz8/HwaNmzI3Llz6d27N3/9618pLCykYsWK9n38+eef6dChAzk5OXh4eDB79mxSUlKoWrWqm/eidMeOHSM6OhqAwsJCYmNj6d69Ox999BFPPfUUmZmZ9OrVi5CQENauXevmaq8uNjaWzz//nKysLAIDAxk/fjxvvvkmzz77rP1nNnfuXHeXiVz4dHTKykV6Aq9iO7X4rjFmcmnzt2rVyugozLcWHYX51hIREUFycrLrh2Q3xqwCVjlzG0opx3B7B6JS6uagYaCUAjQMlFIWDQOlFKBhoJSyaBgopQANA6WURcNAKQVoGCilLBoGSilAw0ApZdEwUEoBGgZKKYuGgVIK0DBQSlk0DJRSgIaBUsqiYaCUAjQMlFIWDQOlFKBhoJSyOPXuyNfKy8uLOnXquLsMh1uzZo27S3CaCyM53W7Onz/v7hKcorRbwGvLQCkFaBgopSwaBkopQMNAKWXRMFBKARoGSimLhoFSCtAwUEpZNAyUUoCGgVLKomGglAI0DJRSFg0DpRSgYaCUsmgYKKUADQOllEXDQCkFaBgopSwaBkopQMNAKWXRMFBKARoGSimLhoFSCrjJxk1wpOzsbJ544gn279+PiDB37lzWr19PQkICvr6+AEyYMIHu3btz4sQJBg8eTEpKCg8//DCvvPKKm6svKS4ujkqVKuHh4YGnpyfTpk0jJyeHGTNmkJmZSa1atRg9ejQ+Pj6cPXuWWbNmcezYMcqVK8eTTz5J/fr1AZg1axbJyclUq1aN1157zc17VdLhw4cZOnQox44dQ0QYPnw4Tz/9NCdPnmTgwIH8+OOP1K9fn//85z/UqFGD6dOns3DhQgAKCws5cOAAx44do2bNmm7ek5IOHjzIkCFD7K/T09N5/vnn+emnn1i9ejXlypWjUaNGzJ07l+rVq7Nx40ZeeOEF8vPzKV++PJMnTyYqKsoltYoxxjkrFnkX6A0cN8a0KMsyYWFhZvv27Q7Z/vDhw2nfvj2PPvoo+fn55OXlMWvWLHx8fHjmmWdKzJubm0taWhr79u1j//79Dg+DGx1EJS4ujmnTplG1alX7tPnz5+Pj40NMTAzLly/n7NmzDBkyhPfff5+KFSvy0EMPceTIEd5++20mTJgAwL59+6hYsSIzZ850WBg4ahCVjIwMMjIyCAsLIycnhzZt2rB8+XLef/99atasyZgxY5g6dSqnTp1iypQpJZZduXIlr732Ghs2bHBILeCcQVSKiopo0qQJn3/+OQcPHiQqKgovLy+ef/55ACZNmkRqaip16tShbt267Nu3j759+/Ltt986rIb77ruPXbt2yeXec+ZhwntAdyeu/4pOnz7Ntm3bGDp0KADly5enevXqV5y/cuXKtG/fnooVK7qmQAfYuXOn/RMjKiqKnTt3ArZP2JYtWwIQEBDA8ePHyc7OBqB58+ZUqVLFHeVeVd26dQkLCwOgSpUqNG3alKNHj7JixQr7J+uQIUP45JNPLll28eLFPPTQQy6t93ps2rSJRo0aERgYSOfOnfHysjXMIyIiOHr0KAAhISHUrVsXgGbNmnH+/Hl++eUXl9TntDAwxmwBTjpr/aVJT0/H19eXuLg42rZtS3x8PLm5uQDMnTuXiIgI4uLiOHXqlDvKu2YiwoQJExg9ejTr1q0DbIdBF5rENWrUsP/BN2jQgMTERAC++eYbMjMzOXHihFvqvl7p6emkpqYSGRnJsWPH7H8cfn5+HDt2rMS8eXl5rF27ln79+rmj1GuydOlSBgwYcMn0+fPn07Vr10umf/zxxwQHB1OhQgVXlOf+DkQRGSEiySKSnJWV5ZB1FhYWkpqayuOPP05iYiKVK1dm+vTpDB8+nH379pGYmIifnx9jx451yPacbfLkycyYMYPnn3+e1atXs2/fvhLviwgitpZfTEwMubm5/OUvf2HVqlU0bNgQDw+3/5jL7OzZswwYMICXX365xGERlNzPC1auXEn79u1vur6CX8vPz2fVqlVER0eXmP7SSy/h5eXFwIEDS0zfv38/48aN4/XXX3dZjW7/LTHGvGWMCTfGhF/o2LtR/v7++Pv7ExERAUB0dLT9WMzT0xMPDw+GDRtGSkqKQ7bnbHfccQcA1atXJzIykm+++Ybq1atz8qSt4XXy5EmqVasGgLe3N0899RQvv/wyTz/9NGfOnLllBrMtKCigf//+xMbGEhMTA0CdOnXIyMgAbP0KtWvXLrHMf/7zn0v+kG5G69atIzg4uMTP4oMPPmD16tW8++67JULu6NGjDBo0iLfffptGjRq5rEa3h4Ez+Pn5ERAQwMGDBwHbsVpQUJD9lwpgxYoVNGvWzF0lltn58+c5d+6c/XlaWhqBgYG0adOGzZs3A7B582Z78OXm5lJQUADAhg0baNasGd7e3m6p/VoYY3j88ccJCgri2WeftU9/4IEHmD9/PmBrTvfp08f+3unTp9myZcstMRL0kiVLShwirFu3jldffZUPP/ywxM8nOzubmJgYJk6cSLt27Vxao9POJgCISAPgU3ecTUhLS+OJJ56goKCABg0a8OabbzJ69Gj27NmDiBAYGMjrr79uPx5t2rQpOTk55OfnU61aNVauXElQUJBDarmRswk///wzU6dOBWzDaXfo0IH+/fuTk5PD9OnTycrKolatWowaNYoqVarw9ddfM3PmTESEO++8kyeffBIfHx8AXn75Zfbu3UtOTg7VqlVj4MCBdO7c+Yb2zVF/iNu2beP++++nZcuW9sOaSZMmERkZycCBAzl06BD169dn8eLF9kOC9957j7Vr17Jo0SKH1HAxR55NyM3NpWnTpuzdu9fegmvZsiW//PKLfV8iIiKYOXMmU6dOZfr06TRu3Ni+/IoVKy5pEV2v0s4mOPPU4iIgCvAFjgHjjTHzSlvGkWFwM7nRU4s3s1vhU/l6OOPU4s2gtDC44peOROR14IpJYYx5urSNGmMGlblCpZTblfYNxGSXVaGUcrsrhoEx5v2LX4uItzEmz/klKaXc4apnE0SknYjsB76yXgeLyBtOr0wp5VJlObX4KtANOAFgjEkDOjqxJqWUG5TpewbGmMO/mlTkhFqUUm5UlkuYD4tIe8CISDngz8AB55allHK1srQM/gQ8CfgDPwEh1mul1G3kqi0DY0wWMNgFtSil3KgsZxMaichKEckUkeMi8omIuO7qCaWUS5TlMGEh8CFQF6gHLAEc/2VwpZRblSUMvI0xHxhjCq3Hv4Fb55ZASqkyKe3ahAt3i1gtImOBxdiuVXgIWOWC2pRSLlRaB2IKtj/+C1c4xV30ngH+7qyilFKuV9q1CQ1dWYhSyr3KNG6CiLQAmnFRX4ExZr6zilJKud5Vw0BExmO7SUkzbH0FPYBtgIaBUreRspxN6A/8HvjZGPMoEAxUc2pVSimXK0sYnDPGFAOFIlIVOA7c6dyylFKuVpY+g2QRqQ68je0Mw1ngC2cWpZRyvbJcm/CE9XSuiKwBqhpj9ji3LKWUq5X2paOw0t4zxuxyTklKKXcorWUwo5T3DPA7B9eCh4cHlSpVcvRq3e52vZ04cMnYh7eLWrVqubsEp/j18HQXK+1LR52cUo1S6qZ0Ww6vppS6dhoGSilAw0ApZSnLnY5ERB4WkRes14EiEuH80pRSrlSWlsEbQDvgwtiJOcBsp1WklHKLsnwDMdIYEyYiuwGMMadEpLyT61JKuVhZWgYFIuKJNSKziNQCip1alVLK5coSBjOBj4DaIjIZ2+XL/3RqVUoplyvLtQkLRCQF22XMAjxojNERlZS6zZTl5iaBQB6w8uJpxphDzixMKeVaZelA/H/878aoFYGGwNdAcyfWpZRysbIcJrS8+LV1NeMTV5hdKXWLuuZvIFqXLkc6oRallBuVpc/gLxe99ADCsI3GrJS6jZSlz6DKRc8LsfUhLHNOOUopdyk1DKwvG1Uxxox2UT1KKTe5Yp+BiHgZY4qAe11Yj1LKTUprGezE1j+QKiIrsA3FnnvhTWPMcifXppRyobL0GVQETmC75+GF7xsYQMNAqdtIaWFQ2zqTsJeSozFjvVZK3UZKCwNPwIeSIXCBhoFSt5nSvnSUYYyZaIyZcJnHRJdVeIO+/vprQkJC7I+qVavy6quvkpaWRrt27WjZsiUPPPAAZ86ccXepZfLYY4/h5+dHq1at7NPS0tK49957CQ4Opk+fPiX2Zc+ePdx77720bNmS4OBgzp8/746yL+vZZ5+lZcuWdOpU8kbc8+bNo0OHDkRFRfF///d/ABw+fJhGjRrRuXNnOnfuzJgxY+zzx8bG0rlzZ6KiohgzZgxFRUUu3Y/SnD9/nnbt2hEWFkZwcDATJkwAYNiwYdx11120bt2a1q1bk5qaCsDChQsJDQ0lJCSEDh06kJaW5rJaxZjLf8iLyG5jTOh1r1jkTmwjNdfB1pJ4yxjzWmnLhIeHm+Tk5Ovd5FUVFRXh7+/Pjh076N+/P9OnT+f+++/n3Xff5YcffrD/4jlacbHjbv+wZcsWfHx8GDp0KHv22Aa2ioyM5KWXXrLvS3p6OhMnTqSwsJDw8HDef/99goODOXHiBNWrV8fT09Nh9dzIuAmJiYl4e3vz5z//mU2bNgGwfft2XnvtNT744AMqVKhAVlYWvr6+HD58mCFDhtjnu1hOTg5VqlTBGMPw4cPp3bs3Dz744HXXBY4bN8EYQ25uLj4+PhQUFHD//ffz8ssv89Zbb9GrVy/69etXYv7//ve/BAUFUaNGDdasWcPEiRP573//65BawPa7kpKSctnBE0prGfz+BrdbCIwyxjQD2gJPikizG1znDdm4cSONGzemfv36HDx4kI4dOwLQpUsXli27Nb5H1bFjR2rWrFli2q/3ZflyW9/uunXr7C0CgDvuuMOhQXCj2rZtS40aNUpMmz9/PiNHjqRChQoA+Pr6XnU9VarYvhdXWFhIfn5+qQOFuJqI4OPjA0BBQQEFBQWl1te+fXv7/0lkZCRHjx51SZ1QShgYY07eyIqNMRkXhmAzxuQABwD/G1nnjVq8eDGDBtlu5di8eXM++eQTAJYsWcLhw4fdWdoNuXhfli5dat+Xb775BhGhe/fuhIeHM23aNHeWWSbfffcdO3bsoFevXsTExNibzwCHDh2iS5cuxMTEsGPHjhLLDRo0iFatWuHj40Pv3r1dXHXpioqKaN26NfXq1aNz585ERtou7XnhhRcIDQ1l1KhR/PLLL5csl5CQQLdu3VxWp0tulS4iDYBQYMdl3hshIskikpyZmem0GvLz81mxYgUDBgwA4N133+WNN96gdevW5OTkUL78rXtbx3feeYc5c+bQpk2bEvtSWFjI9u3b+fe//82WLVv4+OOP2bhxo5urLV1RURHZ2dl8+umnjBs3jri4OIwx1K5dm6SkJNavX8+LL77IE088QU5Ojn25RYsWsXv3bvLz89m2bZsb9+BSnp6epKSkkJ6eTlJSEnv37mXy5Mns3buXxMRETp48eUlQb968mYSEBP71r3+5rE6nh4GI+GC7luEZY8wlvXTGmLeMMeHGmHBnjm+3evVqwsLCqFOnDgBNmzZl3bp1pKSkMGjQIBo3buy0bTtb06ZNWbt2LUlJSQwcONC+L/7+/nTo0AFfX1+8vb3p0aMHu3fvdnO1patbty49e/ZERAgNDcXDw4OTJ09SoUIF++FRq1ataNCgAd9//32JZStWrEi3bt1Yu3atO0q/qurVqxMVFcW6deuoW7cuIkKFChUYOnQoSUlJ9vn27NlDXFwcy5Yt44477nBZfU4NAxEphy0IFrj7G4uLFi2yHyIAHD9+HLB17k2aNIk//elP7irthl28L5MnT2bEiBEAdOvWjb1795KXl0dhYSFbtmwhKCjInaVeVffu3dm+fTtgO2TIz8+nZs2anDhxwn6W4Mcff+SHH34gMDCQ3NxceydmYWEhGzZsoEmTJm6r/9cyMzPJzs4G4Ny5c2zYsIF77rmHjIwMwNbB+Mknn9C8ue1eQYcOHeIPf/gDCQkJ3H333S6ttSzfQLwuYuslmQccMMa87KztlEVubi7r16/nzTfftE9btGgRs2fbhn+IiYnh0UcfdVd51yQ2NpbPP/+crKwsAgMDGT9+PLm5ubzxxhsAREdH2/elRo0aPPPMM0RGRiIi9OjRg169ermz/BLi4+P54osvOHnyJK1bt2bUqFEMHDiQv/zlL3Tq1Ily5crx2muvISIkJiYybdo0vLy88PDwYMqUKdSoUYPMzEyGDh1Kfn4+xcXFtG/fniFDhrh71+wyMjIYNmwYRUVFGGPo378/vXr1okuXLlw4LG7VqpX95zdp0iROnDjBU089BYCXl9cl/SPOcsVTize8YpH7gK3Al/zv1urPGWNWXWkZZ59adBdHnlq82eiQ7LeW0k4tOq1lYIzZxuW/vaiUugnpwKtKKUDDQCll0TBQSgEaBkopi4aBUgrQMFBKWTQMlFKAhoFSyqJhoJQCNAyUUhYNA6UUoGGglLJoGCilAA0DpZRFw0ApBWgYKKUsGgZKKUDDQCll0TBQSgEaBkopi4aBUgpw4t2Rr5ezbt3uTpcbR+92cbveUrxcuXLuLsHltGWglAI0DJRSFg0DpRSgYaCUsmgYKKUADQOllEXDQCkFaBgopSwaBkopQMNAKWXRMFBKARoGSimLhoFSCtAwUEpZNAyUUoCGgVLKomGglAI0DJRSFg0DpRSgYaCUsmgYKKUADQOllOW2DINhw4ZRp04dWrZsaZ82btw4goODCQ0NpVu3bvz000/29zZv3kxoaCgtWrQgKirKDRWXXXZ2NrGxsYSEhBAaGsqOHTuYNGkSjRs3JjIyksjISNasWQPA4sWL7dMiIyOpXLkyaWlpbt6Dyzt//jzt2rUjLCyM4OBgJkyYUOL9Z555hurVq9tfv/LKK7Rq1YrQ0FC6du3Kjz/+6OKKS5o3bx7Hjh3jyy+/tE8bP348R44cYffu3ezevZsePXoA4OXlxXvvvceePXvYv38/Y8eOtS9TrVo1lixZwoEDB9i/fz9t27YF4KWXXuLAgQOkpaWxfPlyqlWr5vidMMY45QFUBHYCacA+YMLVlmndurUpLi6+4cfmzZtNcnKyad68uX1adna2/fmrr75qRowYYYqLi83JkydNUFCQSU9PN8XFxebnn392SA0XP/Ly8hz2GDx4sJk9e7bJy8sz2dnZ5qeffjLPPfec+ec//1nqcjt37jQNGzZ0aC15eXmmoKDAIY/8/Hxz6tQpU1BQYPLy8kybNm3M1q1bTUFBgfniiy9MbGysqVy5sn3+9evXm9OnT5uCggLz+uuvmwEDBjisloKCAgNc06NDhw4mNDTUfPnll/Zp48ePN6NGjbpk3kGDBplFixYZwFSqVMn88MMPpn79+gYw7733nnnssccMYMqVK2eqVatmANOlSxfj6elpADNlyhQzZcqUa67xwuNKf3/ObBn8AvzOGBMMhADdRaStE7dn17FjR2rWrFliWtWqVe3Pc3NzEREAFi5cSHR0NIGBgQDUrl3bFSVel9OnT7Nt2zaGDh0KQPny5Ut8Wpbmww8/pH///s4r7gaJCD4+PgAUFBRQUFCAiFBUVMTYsWOZMmVKifmjoqLw9vYGIDIykiNHjri85ott3bqVkydPlmleYwyVK1fG09OTSpUqkZ+fz5kzZ6hatSodO3Zk3rx5gO3/4fTp0wCsX7+eoqIiABITEwkICHD4PjgtDIzNWetlOevh1uGS/vGPfxAYGMjChQuZOHEiAAcPHuTUqVN06tSJ8PBw5s+f784SS5Weno6vry9xcXG0bduW+Ph4cnNzAZg7dy4RERHExcVx6tSpS5ZdtmwZf/jDH1xd8jUpKiqidevW1KtXj86dOxMZGcns2bPp3bs3devWveJyCQkJdO/e3YWVlt3IkSNJS0tj3rx59uBeunQpubm5ZGRkcOjQIaZPn86pU6do2LAhmZmZJCQksGvXLt5++2174F1s2LBhrF692uG1OrXPQEQ8RSQVOA6sN8bscOb2rmby5MkcOnSI2NhYZs2aBUBhYSG7du3i008/Zc2aNUyaNImDBw+6s8wrKiwsJDU1lccff5zExEQqV67M9OnTGT58OPv27SMxMRE/P78Sx6AAO3fuxNvbm+bNm7up8rLx9PQkJSWF9PR0kpKS2Lp1K8uWLWPkyJFXXGbBggWkpKQwatQoF1ZaNnPmzKFx48aEhISQkZHBjBkzAIiIiKCoqIh69erRsGFDRo0aRcOGDfHy8iIsLIw5c+YQFhZGbm7uJT/L5557jsLCQhYsWODwep0aBsaYImNMCBAARIhIi1/PIyIjRCRZRJIzMzOdWY7d4MGDWb58OQABAQF07dqVypUr4+vrS4cOHW7aTjZ/f3/8/f2JiIgAIDo6mtTUVOrUqYOnpyceHh4MGzaMlJSUEsstXbqUAQMGuKPk61K9enWioqLYvHkz3333HU2bNqVJkybk5eXRtGlT+3wbN25kypQpfPTRR1SoUMGNFV/e8ePHKS4uxhjD22+/bf+5xcbGsmbNGgoLC8nMzGT79u2Eh4dz5MgRjhw5ws6dOwHbzy0sLMy+vkceeYTevXszePBgp9TrkrMJxphsYBNwSVvOGPOWMSbcGBPuzEE8v/nmG/vzTz75xP5L1bdvX7Zv305hYSF5eXns3LmToKAgp9VxI/z8/AgICLC3XDZt2kRQUBAZGRn2eVasWEGzZs3sr4uLi1m2bNlNHwaZmZlkZ2cDcO7cOTZs2EBYWBhHjhzh22+/5dtvv8Xb25uvvvoKgN27d/PEE0+wfPnym7afx8/Pz/48OjqavXv3AnDo0CF+97vfAeDt7U3btm356quvOHbsGIcPH+buu+8G4Pe//z379+8HoFu3bvztb3+jT58+nDt3zin1Om0UZhGpBRQYY7JFpBLQBZjqrO1dLDY2ls2bN5OVlcWdd97Jiy++yOrVq/n666/x8PCgfv36zJkzB4CgoCC6detGcHAwHh4ePPbYY7RocUkD5qYxY8YMHn30UQoKCmjQoAFvvvkmo0ePZs+ePYgIgYGBvP766/b5t23bRkBAAA0bNnRj1VeXkZHBsGHDKCoqwhhD//796dWr1xXnHzt2LGfPnmXgwIEABAYG8tFHH7mq3EssXLiQqKgofH19OXz4MOPHjycqKoqQkBCMMaSnpxMXFwfA7NmzSUhIYO/evYgICQkJ9lOSTz31FAsWLKB8+fJ8//33PProowDMmjWLChUqsH79esDWiRgfH+/QfRBnDYEuIq2A9wFPbC2QD40xE0tbJjw83CQlJTmlHnc6f/68u0twmtt16PLbdb8AjDFyuelOaxkYY/YAoc5av1LKsW7LbyAqpa6dhoFSCtAwUEpZNAyUUoCGgVLKomGglAI0DJRSFg0DpRSgYaCUsmgYKKUADQOllEXDQCkFaBgopSwaBkopQMNAKWXRMFBKARoGSimLhoFSCtAwUEpZNAyUUoCGgVLKomGglAKcOG7C9RCRTOBHF23OF8hy0bZcSffr1uPKfatvjLns0GU3VRi4kogkG2PC3V2Ho+l+3Xpuln3TwwSlFKBhoJSy/JbD4C13F+Akul+3npti336zfQZKqZJ+yy0DpdRFNAyUUsBvMAxEpLuIfC0i34rIWHfX4ygi8q6IHBeRve6uxZFE5E4R2SQi+0Vkn4j82d01OYKIVBSRnSKSZu3XBLfX9FvqMxART+Ag0AU4AiQBg4wx+91amAOISEfgLDDfGNPC3fU4iojUBeoaY3aJSBUgBXjwVv+ZiYgAlY0xZ0WkHLAN+LMxJtFdNf3WWgYRwLfGmO+NMfnAYqCvm2tyCGPMFuCku+twNGNMhjFml/U8BzgA+Lu3qhtnbM5aL8tZD7d+Mv/WwsAfOHzR6yPcBr9YvxUi0gAIBXa4uRSHEBFPEUkFjgPrjTFu3a/fWhioW5SI+ADLgGeMMWfcXY8jGGOKjDEhQAAQISJuPbz7rYXBUeDOi14HWNPUTcw6pl4GLDDGLHd3PY5mjMkGNgHd3VnHby0MkoC7RKShiJQHBgIr3FyTKoXV0TYPOGCMednd9TiKiNQSkerW80rYOrW/cmdNv6kwMMYUAiOBtdg6oj40xuxzb1WOISKLgC+Ae0TkiIg85u6aHORe4I/A70Qk1Xr0dHdRDlAX2CQie7B9SK03xnzqzoJ+U6cWlVJX9ptqGSilrkzDQCkFaBgopSwaBkopQMNAKWXRMLiFiEiRdWptr4gsERHvG1jXeyLS33r+jog0K2XeKBFpfx3bSBcR37JO/9U8Z0t7/zLzvygio6+1RvU/Gga3lnPGmBDrqsR84E8XvykiXtezUmPM41e5CjAKuOYwULcWDYNb11agifWpvVVEVgD7rYtfpolIkojsEZE4sH2TT0RmWfdy2ADUvrAiEdksIuHW8+4issu6zn6jdXHQn4BnrVZJB+vbc8usbSSJyL3WsneIyDrr+vx3ALnaTojIxyKSYi0z4lfvvWJN3ygitaxpjUVkjbXMVhFp6pD/TQXGGH3cIg/grPWvF/AJEI/tUzsXaGi9NwJ43npeAUgGGgIxwHrAE6gHZAP9rfk2A+FALWxXdV5YV03r3xeB0RfVsRC4z3oeiO2rwgAzgRes572wXZLre5n9SL8w/aJtVAL2AndYrw0w2Hr+AjDLer4RuMt6Hgl8drka9XHtj+tqViq3qWRd8gq2lsE8bM33ncaYH6zpXYFWF/oDgGrAXUBHYJExpgj4SUQ+u8z62wJbLqzLGHOl+yN0BprZLhsAoKp1VWFHbKGDMeb/icipMuzT0yISbT2/06r1BFAM/Mea/m9gubWN9sCSi7ZdoQzbUGWgYXBrOWdsl7zaWX8UuRdPAp4yxqz91XyO/D6/B9DWGHP+MrWUmYhEYQuWdsaYPBHZDFS8wuzG2m72r/8PlGNon8HtZy0Qb132i4jcLSKVgS3AQ1afQl2g02WWTQQ6ikhDa9ma1vQcoMpF860DnrrwQkRCrKdbgFhrWg+gxlVqrQacsoKgKbaWyQUewIXWTSywzdjuY/CDiAywtiEiEnyVbagy0jC4/bwD7Ad2ie3mqG9iawF+BHxjvTcf2xWOJRhjMrH1OSwXkTT+10xfCURf6EAEngbCrQ7K/fzvrMYEbGGyD9vhwqGr1LoG8BKRA8AUbGF0QS62G37sBX4HTLSmDwYes+rbx21y27qbgV61qJQCtGWglLJoGCilAA0DpZRFw0ApBWgYKKUsGgZKKUDDQCll+f+X7/jN2Tl6YwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62338f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8527611604827277"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "353a4378",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000002B6535FD4C0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:121\u001b[0m, in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m InlineBackend\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mclose_figures:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;66;03m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[0;32m    124\u001b[0m         ip \u001b[38;5;241m=\u001b[39m get_ipython()\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:41\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 41\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\backend_bases.py:2295\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2289\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m _get_renderer(\n\u001b[0;32m   2290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[0;32m   2291\u001b[0m         functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m   2292\u001b[0m             print_method, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m   2293\u001b[0m     )\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2295\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     75\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2807\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 2810\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   2814\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3079\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3080\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3082\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3085\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\text.py:1978\u001b[0m, in \u001b[0;36mAnnotation.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1976\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrow_patch\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrow_patch\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m-> 1978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrow_patch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1979\u001b[0m \u001b[38;5;66;03m# Draw text, including FancyBboxPatch, after FancyArrowPatch.\u001b[39;00m\n\u001b[0;32m   1980\u001b[0m \u001b[38;5;66;03m# Otherwise, a wedge arrowstyle can land partly on top of the Bbox.\u001b[39;00m\n\u001b[0;32m   1981\u001b[0m Text\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m, renderer)\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:4485\u001b[0m, in \u001b[0;36mFancyArrowPatch.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   4478\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind_draw_path_function(renderer) \u001b[38;5;28;01mas\u001b[39;00m draw_path:\n\u001b[0;32m   4479\u001b[0m \n\u001b[0;32m   4480\u001b[0m     \u001b[38;5;66;03m# FIXME : dpi_cor is for the dpi-dependency of the linewidth. There\u001b[39;00m\n\u001b[0;32m   4481\u001b[0m     \u001b[38;5;66;03m# could be room for improvement.  Maybe _get_path_in_displaycoord\u001b[39;00m\n\u001b[0;32m   4482\u001b[0m     \u001b[38;5;66;03m# could take a renderer argument, but get_path should be adapted\u001b[39;00m\n\u001b[0;32m   4483\u001b[0m     \u001b[38;5;66;03m# too.\u001b[39;00m\n\u001b[0;32m   4484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dpi_cor \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mpoints_to_pixels(\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m-> 4485\u001b[0m     path, fillable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_path_in_displaycoord\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39miterable(fillable):\n\u001b[0;32m   4488\u001b[0m         path \u001b[38;5;241m=\u001b[39m [path]\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:4453\u001b[0m, in \u001b[0;36mFancyArrowPatch._get_path_in_displaycoord\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4451\u001b[0m     posB \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_xy_units(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_posA_posB[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   4452\u001b[0m     (posA, posB) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((posA, posB))\n\u001b[1;32m-> 4453\u001b[0m     _path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connectionstyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4454\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpatchA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatchA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4455\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpatchB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatchB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4456\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mshrinkA\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinkA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4457\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mshrinkB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinkB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdpi_cor\u001b[49m\n\u001b[0;32m   4458\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4460\u001b[0m     _path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_original)\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:2770\u001b[0m, in \u001b[0;36mConnectionStyle._Base.__call__\u001b[1;34m(self, posA, posB, shrinkA, shrinkB, patchA, patchB)\u001b[0m\n\u001b[0;32m   2765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2766\u001b[0m \u001b[38;5;124;03mCall the *connect* method to create a path between *posA* and\u001b[39;00m\n\u001b[0;32m   2767\u001b[0m \u001b[38;5;124;03m*posB*; then clip and shrink the path.\u001b[39;00m\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(posA, posB)\n\u001b[1;32m-> 2770\u001b[0m clipped_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatchA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatchB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2771\u001b[0m shrunk_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shrink(clipped_path, shrinkA, shrinkB)\n\u001b[0;32m   2772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m shrunk_path\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:2725\u001b[0m, in \u001b[0;36mConnectionStyle._Base._clip\u001b[1;34m(self, path, patchA, patchB)\u001b[0m\n\u001b[0;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patchA\u001b[38;5;241m.\u001b[39mcontains(xy_event)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2724\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2725\u001b[0m     left, right \u001b[38;5;241m=\u001b[39m \u001b[43msplit_path_inout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsideA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2726\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2727\u001b[0m     right \u001b[38;5;241m=\u001b[39m path\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\bezier.py:363\u001b[0m, in \u001b[0;36msplit_path_inout\u001b[1;34m(path, inside, tolerance, reorder_inout)\u001b[0m\n\u001b[0;32m    361\u001b[0m iold \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m    362\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ctl_points) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minside\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctl_points\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m begin_inside:\n\u001b[0;32m    364\u001b[0m     bezier_path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([ctl_points_old[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:], ctl_points])\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:2722\u001b[0m, in \u001b[0;36mConnectionStyle._Base._clip.<locals>.insideA\u001b[1;34m(xy_display)\u001b[0m\n\u001b[0;32m   2720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minsideA\u001b[39m(xy_display):\n\u001b[0;32m   2721\u001b[0m     xy_event \u001b[38;5;241m=\u001b[39m ConnectionStyle\u001b[38;5;241m.\u001b[39m_Base\u001b[38;5;241m.\u001b[39mSimpleEvent(xy_display)\n\u001b[1;32m-> 2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpatchA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy_event\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:165\u001b[0m, in \u001b[0;36mPatch.contains\u001b[1;34m(self, mouseevent, radius)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     subpaths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path()]\n\u001b[1;32m--> 165\u001b[0m inside \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmouseevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmouseevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubpaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inside, {}\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\patches.py:166\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     subpaths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path()]\n\u001b[0;32m    165\u001b[0m inside \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m--> 166\u001b[0m     \u001b[43msubpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_point\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmouseevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmouseevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subpath \u001b[38;5;129;01min\u001b[39;00m subpaths)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inside, {}\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\path.py:531\u001b[0m, in \u001b[0;36mPath.contains_point\u001b[1;34m(self, point, transform, radius)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03mReturn whether the area enclosed by the path contains the given point.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m  the result is not guaranteed to be correct.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 531\u001b[0m     transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrozen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# `point_in_path` does not handle nonlinear transforms, so we\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# transform the path ourselves.  If *transform* is affine, letting\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# `point_in_path` handle the transform avoids allocating an extra\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# buffer.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transform\u001b[38;5;241m.\u001b[39mis_affine:\n",
      "File \u001b[1;32mc:\\users\\vik\\desktop\\cs 4225\\project\\traffic-predict\\.venv\\lib\\site-packages\\matplotlib\\transforms.py:1848\u001b[0m, in \u001b[0;36mAffine2DBase.frozen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrozen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_tree(clf);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e5ee99",
   "metadata": {},
   "source": [
    "# K NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c1a6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2785f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da34b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6407897921781528"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb344b",
   "metadata": {},
   "source": [
    "# MLP \n",
    "This is a fast way to get a neural net modelling \n",
    "Need more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f394991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(2,4,16,32,16,4,2), random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5bfa2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZMUlEQVR4nO3deXRUZbrv8e9DJtEwCaGXhCkhXA6jRKJI98HmiDagqEebIfawbDi0R/Fqg7qWU3dzxKVNe7yiXHRdchsR+xxxgPbiiG0ztNoOGDmtlwheEDWDDQkgMkRJUj73j9opg52EALWroPh91qpl7V1Vez8vpn717ndP5u6IiLRLdgEicnxQGIgIoDAQkYDCQEQAhYGIBNKTXUBT3bp18759+ya7DJGU9cknn7Bz505r7rXjKgz69u1LaWlpsssQSVlFRUUtvqbNBBEBFAYiElAYiAigMBCRgMJARACFgYgEFAYiAigMRCSgMBARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQESAkzAMVq1axYABAygoKGDevHnJLieuUrVtaleCuHtoD2A88CGwFbj1cO8fMWKEh6mhocHz8/P9o48+8oMHD/qwYcO8rKws1HUmSqq2Te2Kr+A71uz3L7SegZmlAQ8BE4BBwJVmNiis9bXF+vXrKSgoID8/n8zMTIqLi1m5cmUyS4qbVG2b2pU4YW4mnANsdfdt7l4HPAFcFuL6DquqqopevXrFpnv27ElVVVUSK4qfVG2b2pU4YYZBLlDRZLoymCcix6GkDyCa2dVmVmpmpTU1NaGuKzc3l4qKb/KpsrKS3NzUyKdUbZvalUAtDSYc6wMYBbzcZPo24LbWPhP2AGJ9fb3n5eX5tm3bYoM2GzduDHWdiZKqbVO74qu1AcQwb7z6DtDfzPKAKqAY+FGI6zus9PR0Fi5cyLhx44hEIkyfPp3Bgwcns6S4SdW2qV2JYx791Q5n4WYXAQ8AacAj7n53a+8vKipy3YVZJDxFRUWUlpYm/pbs7v4i8GKY6xCR+Ej6AKKIHB8UBiICKAxEJKAwEBFAYSAiAYWBiAAKAxEJKAxEBFAYiEhAYSAigMJARAIKAxEBFAYiElAYiAigMBCRgMJARACFgYgEFAYiAigMRCSgMBARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISOOnCYNWqVQwYMICCggLmzZuX7HLiKlXbpnYliLuH8gAeAaqBjW39zIgRIzxMDQ0Nnp+f7x999JEfPHjQhw0b5mVlZaGuM1FStW1qV3wF37Fmv39h9gweBcaHuPwjtn79egoKCsjPzyczM5Pi4mJWrlyZ7LLiIlXbpnYlTmhh4O6vArvDWv7RqKqqolevXrHpnj17UlVVlcSK4idV26Z2JU7SxwzM7GozKzWz0pqammSXI3LSSnoYuHuJuxe5e1FOTk6o68rNzaWioiI2XVlZSW5ubqjrTJRUbZvalUAtDSbE4wH05TgaQKyvr/e8vDzftm1bbNBm48aNoa4zUVK1bWpXfLU2gJie3ChKrPT0dBYuXMi4ceOIRCJMnz6dwYMHJ7usuEjVtqldiWMe/QWP/4LNlgFjgG7ADmCOuy9u7TNFRUVeWloaSj0iAkVFRZSWllpzr7XYMzCz/wm0mBTufkNrK3X3K9tcoYgkXWubCfqJFjmJtBgG7r606bSZneruteGXJCLJcNhdi2Y2ysw+ADYH02ea2cOhVyYiCdWW4wweAMYBuwDc/T3gvBBrEpEkaNNBR+5e8a1ZkRBqEZEkastxBhVm9l3AzSwD+AWwKdyyRCTR2tIzuAa4DsgFPgOGB9MikkIO2zNw953AjxNQi4gkUVv2JuSb2XNmVmNm1Wa20szyE1GciCROWzYTHgeeAs4AegBPA8vCLEpEEq8tYXCqu//e3RuCx38Ap4RdmIgkVmvnJpwePH3JzG4FniB6rsJU4MUE1CYiCdTaAOK7RL/8jWc4/WuT1xy4LayiRCTxWjs3IS+RhYhIcrXp4iZmNgQYRJOxAnd/LKyiRCTxDhsGZjaH6EVKBhEdK5gAvA4oDERSSFv2JkwCxgLb3X0acCbQKdSqRCTh2hIGX7r710CDmXUkepekXof5jIicYNoyZlBqZp2B/010D8N+4M0wixKRxGvLuQkzg6f/y8xWAR3d/f1wyxKRRGvtoKOzWnvN3TeEU5KIJENrPYP/0cprDpwf51pEJIlaO+jonxJZiIgkV9LvtSgixweFgYgACgMRCbTlSkdmZj8xs18H073N7JzwSxORRGpLz+BhYBTQeO/EfcBDoVUkIknRliMQR7r7WWb2XwDu/rmZZYZcl4gkWFt6BvVmlkZwR2YzywG+DrUqEUm4toTBAuAZoLuZ3U309OV7Qq1KRBKuLecm/KeZvUv0NGYD/tnddUclkRTTloub9AZqgeeaznP38jALE5HEassA4gt8c2HUU4A84ENgcIh1iUiCtWUzYWjT6eBsxpktvF1ETlBHfARicOryyBBqEZEkasuYwY1NJtsBZxG9G7OIpJC2jBl0aPK8gegYwopwyhGRZGk1DIKDjTq4+80JqkdEkqTFMQMzS3f3CPC9BNYjIknSWs9gPdHxgb+a2bNEb8V+oPFFd/9DyLWJSAK1ZczgFGAX0WseNh5v4IDCQCSFtBYG3YM9CRs59G7MBNMikkJaC4M0IJtDQ6CRwkAkxbR20NHf3H2uu9/ZzGNuwiqMs1WrVjFgwAAKCgqYN29essuJq1Rtm9qVIO7e7AP4r5Zea8uD6P0Y1wIfAGXALw73mREjRniYGhoaPD8/3z/66CM/ePCgDxs2zMvKykJdZ6KkatvUrvgKvmPNfv9a6xmMPcacaQBucvdBwLnAdWY26BiXeUzWr19PQUEB+fn5ZGZmUlxczMqVK5NZUtykatvUrsRpMQzcffexLNjd/+bBLdjcfR+wCcg9lmUeq6qqKnr1+uYG0j179qSqqiqJFcVPqrZN7UqchFwq3cz6AoXA2828drWZlZpZaU1NTSLKEZFmhB4GZpZN9FyGWe6+99uvu3uJuxe5e1FOTk6oteTm5lJRURGbrqysJDc3qZ2VuEnVtqldCdTSYEI8HkAG8DJwY1veH/YAYn19vefl5fm2bdtigzYbN24MdZ2JkqptU7viq7UBxLYcgXhUzMyAxcAmd78/rPUcifT0dBYuXMi4ceOIRCJMnz6dwYNT44JNqdo2tStxzD2c44fM7B+B14D/yzeXVr/d3V9s6TNFRUVeWloaSj0iAkVFRZSWljZ3IGF4PQN3f53mj14UkeOQbrwqIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISUBiICBDi1ZGPxpdffsnGjRuTXUbcvf32391VLmWcf/75yS4hFPn5+ckuIeHUMxARQGEgIgGFgYgACgMRCSgMRARQGIhIQGEgIoDCQEQCCgMRARQGIhJQGIgIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISOC4ulT6sdi+fTu33347u3btwsyYNGkSP/nJT/jwww+ZO3cutbW15ObmMm/ePLKzs3njjTd44IEHqK+vJyMjg5tuuomRI0cCsGDBAp599ln27t3L+vXrk9wyqK2tZenSpVRVVQEwbdo0+vXrx+rVq1m7di3t2rVj6NChTJ48mbKyMlasWEEkEiEtLY3JkyczcOBAAO69916++OILMjMzAZg9ezYdO3ZMWrs+++wzbr75Znbu3ImZUVxczLRp0/jNb37D6tWrycjIoE+fPtx777107NiRyspKLrzwwthlzIcPH87dd98NwM9+9jOqq6uJRCIUFRUxd+5c0tLSEtaWxYsXM3HiRKqrqxk6dCgATzzxBAMGDACgc+fO7Nmzh8LCQk4//XSWL1/O2WefzaOPPsr1118PQPv27Xn66afp168fkUiE5557jttuuw2AzMxMHnvsMUaMGMGuXbuYOnUqn376aVzbYO4e1wXGFmx2CvAqkEU0dJa7+5zWPjN48GB/8sknj2p9NTU11NTUMGjQIA4cOMDUqVN58MEHueOOO7jppps4++yzeeaZZ6isrOT6669n06ZNdO3ale7du7NlyxauueYaVq9eDcB7771Hjx49uPjii+MSBsd634TFixfTv39/zjvvPBoaGqirq6O8vJwXXniBG264gYyMDPbu3UvHjh0pLy+nY8eOdO7cmaqqKubPn899990HRMNgypQp9O3b95jb1OhY7ptQXV1NdXU1Q4YMYf/+/Vx66aUsWrSI7du3M2rUKNLT05k3bx4At956K5WVlcyYMYNVq1b93bL27dtHhw4dcHdmzpzJRRddxCWXXHLUtR3pfRNGjx7N/v37eeyxx2Jh0NR9993HF198wV133cWpp55KYWEhQ4YMYciQIYeEwciRI1m3bh0ZGRmsXr2ae+65h1WrVnHttdcybNgwrr32WqZOncrll19OcXHxUbXN3a25+WFuJhwEznf3M4HhwHgzOzesleXk5DBo0CAATjvtNPLy8tixYweffvopRUVFAIwaNYo//elPAAwcOJDu3bsDUFBQwFdffUVdXR0AZ555Jjk5OWGVekRqa2vZsmULo0ePBiA9PZ1TTz2VdevWMWHCBDIyMgBiv/C9e/emc+fOAPTo0YO6ujrq6+uTUvvhdO/enSFDhgCQnZ1NQUEB27dvZ/To0aSnRzuthYWFbN++/bDL6tChAwANDQ3U19dj1uzfe2hee+01du/e3eLrU6ZMYdmyZUD0/+lf/vIXvvrqq0Pe8+WXX7Ju3ToA6uvr2bBhAz179gTgsssuY+nSpQAsX76csWPHxr0NoW0meLTLsT+YzAge4XRDvqWqqorNmzczbNgw+vXrx5o1axg7diwvv/xys39Yr7zyCgMHDox1n48nO3fuJDs7myVLllBRUUGfPn248sor2bFjB1u2bOGZZ54hIyODyZMnk5eXd8hn3333Xfr06RMLDIAlS5bQrl07zjrrLCZOnJjwL01LKisrKSsrY/jw4YfMf/rpp5k4cWJsuqKigokTJ5Kdnc2NN97IOeecE3vtqquu4r333uP73/8+EyZMSFTphzV69Gh27NjB1q1b2/yZTp06cckll/Dggw8CkJubS0VFBQCRSIQvvviCrl27smvXrrjVGeoAopmlmdlfgWrgFXcP/T5jtbW1zJ49m1tuuYXs7Gzmzp3Lk08+yZQpU6itrT3kiwGwdetW5s+fz5w5rW7BJM3XX39NeXk5Y8aMYc6cOWRlZfHSSy8RiUQ4cOAAt99+O5MmTWLRokU03eSrqqpixYoV/PSnP43N+/nPf86dd97JLbfcwpYtW3jzzTeT0aS/c+DAAWbOnMmvfvWr2C88wEMPPUR6ejqXXXYZEO39vf766zz//PPccccdzJ49m3379sXev3TpUt5++23q6up44403Et6Ollx55ZWxXkFbpKWlsWzZMhYsWMDHH38cYmWHCjUM3D3i7sOBnsA5Zjbk2+8xs6vNrNTMSj///PNjWl99fT2zZ8/m4osv5oILLgCi234lJSU89dRTTJgwgV69esXev337dmbNmsU999xzyPzjSZcuXejSpUtsG3bEiBF8+umndOnShbPOOgszIz8/HzNj//5oR2z37t08/PDDTJ8+PbYp1LgsgFNOOYWRI0cm9A+tJfX19cycOZNLL72U8ePHx+YvX76cNWvWMH/+/FjvJSsrK9aGoUOH0rt3779rQ1ZWFhdeeGFsczDZ0tLSuOKKKziSsbCSkhK2bNkS6xVANNwb/0bT0tLo1KlTXHsFkKBdi+6+B1gLjG/mtRJ3L3L3osb/0Ue5DubMmUN+fj5XXXVVbH7jP9jXX39NSUkJU6ZMAWDv3r1cd911zJo1i8LCwqNeb9g6derE6aefHtu82bRpEz169KCwsJDNmzcD0VBraGggOzub2tpaFixYwBVXXEH//v1jy4lEIrFf0YaGBt5//31yc3MT36Am3J1bb72Vfv36MWPGjNj8P//5z5SUlFBSUkL79u1j83ft2kUkEgGgvLycTz75hN69e3PgwAGqq6uBaNvWrl1Lv379EtuYFlxwwQVs3rw5tifocO666y46derErFmzDpn/7LPPxv6uJ02axJo1a+Jdaqh7E3KAenffY2btgT8Cv3X351v6zLHsTdiwYQNXXXUV/fv3p127aMbdcMMNlJeX88QTTwAwduxYZs2ahZmxaNEiFi9eTO/evWPLWLRoEV27duX+++/nhRdeoKamhpycHH74wx8yc+bMo6oLjn1vQnl5OUuXLqWhoYGcnBymTZtGVlZWbBwhPT09tgvx+eef58UXX+Q73/lO7POzZ88mKyuL3/72t0QiEdydgQMHMnXq1Ni/1dE6lr0J77zzDlOnTmXAgAGxOm6++Wbmzp1LXV1dbCC0cRfiSy+9xAMPPEB6ejrt2rVj1qxZjB07lpqaGmbMmEFdXR3uzrnnnssvf/nL2CDk0TjSvQmPP/44Y8aMoVu3buzYsYM5c+bwyCOPsGTJEt566y0WLVp0yPs//vhjOnbsSGZmJnv27OEHP/gBe/fupbKykk2bNnHw4EEAFi5cyOLFi8nKyuL3v/89hYWF7N69m+Li4qPu2bW0NyHMMBgGLAXSiPZAnnL3ua195ljC4HimW7KfeFL5luwthUGYexPeB47f/reIHEKHI4sIoDAQkYDCQEQAhYGIBBQGIgIoDEQkoDAQEUBhICIBhYGIAAoDEQkoDEQEUBiISEBhICKAwkBEAgoDEQEUBiISUBiICKAwEJGAwkBEAIWBiAQUBiICKAxEJBDafROOhpnVAPG96XzLugE7E7SuRFK7TjyJbFsfd2/2FuPHVRgkkpmVuntRsuuIN7XrxHO8tE2bCSICKAxEJHAyh0FJsgsIidp14jku2nbSjhmIyKFO5p6BiDShMBAR4CQMAzMbb2YfmtlWM7s12fXEi5k9YmbVZrYx2bXEk5n1MrO1ZvaBmZWZ2S+SXVM8mNkpZrbezN4L2nVn0ms6mcYMzCwN+H/AhUAl8A5wpbt/kNTC4sDMzgP2A4+5+5Bk1xMvZnYGcIa7bzCzDsC7wD+f6P/PzMyA09x9v5llAK8Dv3D3t5JV08nWMzgH2Oru29y9DngCuCzJNcWFu78K7E52HfHm7n9z9w3B833AJiA3uVUdO4/aH0xmBI+k/jKfbGGQC1Q0ma4kBf6wThZm1hcoBN5OcilxYWZpZvZXoBp4xd2T2q6TLQzkBGVm2cAKYJa77012PfHg7hF3Hw70BM4xs6Ru3p1sYVAF9Goy3TOYJ8exYJt6BfCf7v6HZNcTb+6+B1gLjE9mHSdbGLwD9DezPDPLBIqBZ5Nck7QiGGhbDGxy9/uTXU+8mFmOmXUOnrcnOqi9OZk1nVRh4O4NwH8HXiY6EPWUu5clt6r4MLNlwJvAADOrNLN/SXZNcfI94KfA+Wb21+BxUbKLioMzgLVm9j7RH6lX3P35ZBZ0Uu1aFJGWnVQ9AxFpmcJARACFgYgEFAYiAigMRCSgMDiBmFkk2LW20cyeNrNTj2FZj5rZpOD578xsUCvvHWNm3z2KdXxiZt3aOv9b79nf2uvNvP/fzOzmI61RvqEwOLF86e7Dg7MS64Brmr5oZulHs1B3n3GYswDHAEccBnJiURicuF4DCoJf7dfM7Fngg+Dkl383s3fM7H0z+1eIHslnZguDazn8CejeuCAzW2dmRcHz8Wa2ITjPfnVwctA1wOygVzI6OHpuRbCOd8zse8Fnu5rZH4Pz838H2OEaYWb/x8zeDT5z9bdemx/MX21mOcG8fma2KvjMa2b2D3H51xRwdz1OkAewP/hvOrASuJbor/YBIC947Wrgl8HzLKAUyAOuAF4B0oAewB5gUvC+dUARkEP0rM7GZZ0e/PffgJub1PE48I/B895EDxUGWAD8Onh+MdFTcrs1045PGuc3WUd7YCPQNZh24MfB818DC4Pnq4H+wfORwJrmatTjyB9H1a2UpGkfnPIK0Z7BYqLd9/Xu/nEw/wfAsMbxAKAT0B84D1jm7hHgMzNb08zyzwVebVyWu7d0fYQLgEHR0wYA6BicVXge0dDB3V8ws8/b0KYbzOzy4HmvoNZdwNfAk8H8/wD+EKzju8DTTdad1YZ1SBsoDE4sX3r0lNeY4EtxoOks4Hp3f/lb74vn8fztgHPd/atmamkzMxtDNFhGuXutma0DTmnh7R6sd8+3/w0kPjRmkHpeBq4NTvvFzP6bmZ0GvApMDcYUzgD+qZnPvgWcZ2Z5wWdPD+bvAzo0ed8fgesbJ8xsePD0VeBHwbwJQJfD1NoJ+DwIgn8g2jNp1A5o7N38CHjdo9cx+NjMJgfrMDM78zDrkDZSGKSe3wEfABssenHURUR7gM8AW4LXHiN6huMh3L2G6JjDH8zsPb7ppj8HXN44gAjcABQFA5Qf8M1ejTuJhkkZ0c2F8sPUugpIN7NNwDyiYdToANELfmwEzgfmBvN/DPxLUF8ZKXLZuuOBzloUEUA9AxEJKAxEBFAYiEhAYSAigMJARAIKAxEBFAYiEvj/wm7D8zYPSz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49236e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5919983401915696"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7199e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
